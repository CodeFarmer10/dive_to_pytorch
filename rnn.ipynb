{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn,optim\n",
    "from torch.utils import data\n",
    "import numpy as np\n",
    "import random\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'想要有直升机\\n想要和你飞到宇宙去\\n想要和你融化在一起\\n融化在宇宙里\\n我每天每天每'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with zipfile.ZipFile(\"data/jaychou_lyrics.txt.zip\") as zin:\n",
    "    with zin.open(\"jaychou_lyrics.txt\") as f:\n",
    "        corpus_chars=f.read().decode(\"utf-8\")\n",
    "corpus_chars[:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_chars=corpus_chars.replace(\"\\n\",\" \").replace(\"\\r\",\" \")\n",
    "corpus_chars=corpus_chars[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'想要有直升机 想要和你飞到宇宙去 想要和你融化在一起 融化在宇宙里 我每天每天每'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_chars[:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2char=list(set(corpus_chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "char2id=dict([(v,k) for k,v in enumerate(id2char)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(char2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_num=len(id2char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1027"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_index=[char2id[c] for c in corpus_chars]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "想要有直升机 想要和你飞到宇宙去 想要和\n"
     ]
    }
   ],
   "source": [
    "sample=corpus_index[:20]\n",
    "sample_chars=\"\".join([id2char[i] for i in sample])\n",
    "print(sample_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_iter_random(corpus_indices,batch_size,num_steps,device=None):\n",
    "    data_num=(len(corpus_indices)-1)//num_steps\n",
    "    batch_num=data_num//batch_size\n",
    "    example_indics=list(range(data_num))\n",
    "    random.shuffle(example_indics)\n",
    "    \n",
    "    def _data(pos):\n",
    "        return corpus_indices[pos:pos+num_steps]\n",
    "    \n",
    "    if device is None:\n",
    "        device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    for i in range(batch_num):\n",
    "        i=i*batch_size\n",
    "        batch_indices=example_indics[i:i+batch_size]\n",
    "        X=[_data(j*num_steps) for j in batch_indices]\n",
    "        Y=[_data(j*num_steps+1) for j in batch_indices]\n",
    "        \n",
    "        yield torch.tensor(X,dtype=torch.float32,device=device),torch.tensor(Y,dtype=torch.float32,device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.,  1.,  2.,  3.,  4.,  5.],\n",
      "        [12., 13., 14., 15., 16., 17.]]) tensor([[ 1.,  2.,  3.,  4.,  5.,  6.],\n",
      "        [13., 14., 15., 16., 17., 18.]])\n",
      "tensor([[ 6.,  7.,  8.,  9., 10., 11.],\n",
      "        [18., 19., 20., 21., 22., 23.]]) tensor([[ 7.,  8.,  9., 10., 11., 12.],\n",
      "        [19., 20., 21., 22., 23., 24.]])\n"
     ]
    }
   ],
   "source": [
    "my_seq=list(range(30))\n",
    "for x,y in data_iter_random(my_seq,num_steps=6,batch_size=2):\n",
    "    print(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_iter_consecutive(corpus_indices,batch_size,num_steps,device=None):\n",
    "    if device is None:\n",
    "        device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    corpus_indices=torch.tensor(corpus_indices,dtype=torch.float32,device=device)\n",
    "    batch_len=len(corpus_indices)//batch_size\n",
    "    indices=corpus_indices[0:batch_size*batch_len].view(batch_size,batch_len)\n",
    "    epoch_size=(batch_len-1)//num_steps\n",
    "    for i in range(epoch_size):\n",
    "        i=i*num_steps\n",
    "        X=indices[:,i:i+num_steps]\n",
    "        Y=indices[:,i+1:i+num_steps+1]\n",
    "        yield X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.,  1.,  2.,  3.,  4.,  5.],\n",
      "        [15., 16., 17., 18., 19., 20.]]) tensor([[ 1.,  2.,  3.,  4.,  5.,  6.],\n",
      "        [16., 17., 18., 19., 20., 21.]])\n",
      "tensor([[ 6.,  7.,  8.,  9., 10., 11.],\n",
      "        [21., 22., 23., 24., 25., 26.]]) tensor([[ 7.,  8.,  9., 10., 11., 12.],\n",
      "        [22., 23., 24., 25., 26., 27.]])\n"
     ]
    }
   ],
   "source": [
    "my_seq=list(range(30))\n",
    "for x,y in data_iter_consecutive(my_seq,num_steps=6,batch_size=2):\n",
    "    print(x,y)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(x,n_class,dtype=torch.float32):\n",
    "    x=x.long()\n",
    "    res=torch.zeros(x.shape[0],n_class,dtype=dtype,device=x.device)\n",
    "    res.scatter_(1,x.view(-1,1),1)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 1.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=torch.tensor([0,2])\n",
    "one_hot(x,vocab_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_onehot(X,n_class):\n",
    "    return [one_hot(X[:,i],n_class) for i in range(X.shape[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_inputs,num_hiddens,num_outputs=vocab_num,256,vocab_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_params():\n",
    "    def _one(shape):\n",
    "        ts=torch.tensor(np.random.normal(0,0.01,shape),dtype=torch.float32,device=device)\n",
    "        return nn.Parameter(ts,requires_grad=True)\n",
    "    \n",
    "    W_hh=_one((num_hiddens,num_hiddens))\n",
    "    W_xh=_one((num_inputs,num_hiddens))\n",
    "    b_h=nn.Parameter(torch.zeros(num_hiddens,dtype=torch.float32,device=device))\n",
    "    \n",
    "    W_hy=_one((num_hiddens,num_outputs))\n",
    "    b_y=nn.Parameter(torch.zeros(num_outputs,dtype=torch.float32,device=device))\n",
    "    \n",
    "    return [W_hh,W_xh,b_h,W_hy,b_y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_rnn_state(batch_size,num_hiddens,device):\n",
    "    return (torch.zeros((batch_size,num_hiddens),device=device),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnn(inputs,state,params):\n",
    "    W_hh,W_xh,b_h,W_hy,b_y=params\n",
    "    H,=state\n",
    "    output=[]\n",
    "    for X in inputs:\n",
    "        H=torch.tanh(torch.matmul(X,W_xh)+torch.matmul(H,W_hh)+b_h)\n",
    "        Y=torch.matmul(H,W_hy)+b_y\n",
    "        output.append(Y)\n",
    "    return output,(H,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 torch.Size([2, 1027])\n"
     ]
    }
   ],
   "source": [
    "X=torch.arange(10).view(2,5)\n",
    "inputs=to_onehot(X,vocab_num)\n",
    "print(len(inputs),inputs[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 torch.Size([2, 1027]) torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "state=init_rnn_state(X.shape[0],num_hiddens,device)\n",
    "inputs=to_onehot(X.to(device),vocab_num)\n",
    "params=get_params()\n",
    "outputs,state_new=rnn(inputs,state,params)\n",
    "print(len(outputs),outputs[0].shape,state_new[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_rnn(prefix,num_chars,rnn,params,state,num_hiddens,\n",
    "                vocab_size,device,id2char,char2id):\n",
    "    state=init_rnn_state(1,num_hiddens,device)\n",
    "    outputs=[char2id[prefix[0]]]\n",
    "    for t in range(num_chars+len(prefix)-1):\n",
    "        X=to_onehot(torch.tensor([[outputs[-1]]],device=device),vocab_size)\n",
    "        (Y,state)=rnn(X,state,params)\n",
    "        if t<len(prefix)-1:\n",
    "            outputs.append(char2id[prefix[t+1]])\n",
    "        else:\n",
    "            outputs.append(int(Y[0].argmax(dim=1).item()))\n",
    "    return \"\".join([id2char[i] for i in outputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'分开蔓墟鲜直找誓被糗给呜'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_rnn(\"分开\",10,rnn,params,init_rnn_state,num_hiddens,vocab_num,device,id2char,char2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_clipping(params,theta,device):\n",
    "    norm=torch.tensor([0.0],device=device)\n",
    "    for param in params:\n",
    "        norm+=(param.grad.data**2).sum()\n",
    "    norm=norm.sqrt().item()\n",
    "    if norm > theta:\n",
    "        for param in params:\n",
    "            param.grad.data*=(theta/norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_predict_rnn(rnn,get_params,init_rnn_state,num_hiddens,vocab_size,device,\n",
    "                          corpus_indices,id2char,char2id,is_random_iter,num_epochs,num_steps\n",
    "                          ,lr,clipping_theta,batch_size,pred_period,pre_len,prefixes):\n",
    "    if is_random_iter:\n",
    "        data_iter_fn=data_iter_random\n",
    "    else:\n",
    "        data_iter_fn=data_iter_consecutive\n",
    "    params=get_params()\n",
    "    loss=nn.CrossEntropyLoss()\n",
    "    optimizer=optim.SGD(params,lr)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        if not is_random_iter:\n",
    "            state=init_rnn_state(batch_size,num_hiddens,device)\n",
    "        l_sum,n,start=0.0,0,time.time()\n",
    "        data_iter=data_iter_fn(corpus_indices,batch_size,num_steps,device)\n",
    "        for X,Y in data_iter:\n",
    "            if is_random_iter:\n",
    "                state=init_rnn_state(batch_size,num_hiddens,device)\n",
    "            else:\n",
    "                for s in state:\n",
    "                    s.detach_()\n",
    "            inputs=to_onehot(X,vocab_size)\n",
    "            outputs,state=rnn(inputs,state,params)\n",
    "            outputs=torch.cat(outputs,dim=0)\n",
    "            y=torch.transpose(Y,0,1).contiguous().view(-1)\n",
    "            l=loss(outputs,y.long())\n",
    "            \n",
    "            if params[0].grad is not None:\n",
    "                for param in params:\n",
    "                    param.grad.data.zero_()\n",
    "            l.backward()\n",
    "            grad_clipping(params,clipping_theta,device)\n",
    "            optimizer.step()\n",
    "            l_sum+=l.item()*y.shape[0]\n",
    "            n+=y.shape[0]\n",
    "        if (epoch+1)%pred_period==0:\n",
    "            print(\"epoch %d,loss %f,time %.2f sec\" %(epoch+1,l_sum/n,time.time()-start))\n",
    "            for prefix in prefixes:\n",
    "                print(\"-\",predict_rnn(prefix,pred_len,rnn,params,init_rnn_state,\n",
    "                                     num_hiddens,vocab_size,device,id2char,char2id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs, num_steps, batch_size, lr, clipping_theta = 250, 35, 32, 1e2, 1e-2\n",
    "pred_period, pred_len, prefixes = 50, 50, ['分开', '不分开']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 50,loss 4.210980,time 2.58 sec\n",
      "- 分开 我不要再想 我不能 想你 我不要我想多 我不要你的 我想能 你爱 我不要我想 我不要再想 我不能 \n",
      "- 不分开 我想想你的  不知 你不么 爱什么 我想要你的  不知 你不么 我爱 我不要再不 我不要再想 我不\n",
      "epoch 100,loss 2.333604,time 2.52 sec\n",
      "- 分开 一颗两 干步的话旧语言 娘你的让我疯狂的可爱女人 坏坏的让我疯狂的可爱女人 坏坏的让我疯狂的可爱女\n",
      "- 不分开吗 我爱你的爱你在西元前 深埋的美索著多 牧草有没有 我马儿有些瘦 我不要的可活 我知道好 说知我 \n",
      "epoch 150,loss 1.037343,time 2.75 sec\n",
      "- 分开 一只用它心步我 我想想这样牵着  这到你说你堡  说去 有 我想好有些瘦 我想要这生远 后知 这去\n",
      "- 不分开吗 我不能再想 我不 我不 我不要再想你 不知不觉 你已经离开我 不知不觉 我跟了这节奏 后知后觉 \n",
      "epoch 200,loss 0.440541,time 2.50 sec\n",
      "- 分开 还金底经心 谁人它 岩烧店的烟味弥漫 隔壁是国术馆 店里面的妈妈桑 茶领刀人跟棍棒 我想耍的有模有\n",
      "- 不分开扫 我后你爸 你打我妈 这样对吗干嘛这样 别必让酒牵鼻子落 瞎 让笑常色的 你想天有多够 如果我遇见\n",
      "epoch 250,loss 0.272470,time 2.49 sec\n",
      "- 分开 一只用 一步两步三步四步望著天 看星星 一颗两颗三颗四颗 连成线背著背默默许下心愿 看远方的星是否\n",
      "- 不分开吗把的胖女巫 用拉丁文念咒语啦啦呜 她养在黑索不达米亚平 伤地一只饿昏的老言鸠 印地安老斑鸠 腿短毛\n"
     ]
    }
   ],
   "source": [
    "train_and_predict_rnn(rnn, get_params, init_rnn_state, num_hiddens,\n",
    "                      vocab_num, device, corpus_index, id2char,\n",
    "                      char2id, True, num_epochs, num_steps, lr,\n",
    "                      clipping_theta, batch_size, pred_period, pred_len,\n",
    "                      prefixes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self,vocab_size,hidden_size):\n",
    "        super(RNN,self).__init__()\n",
    "        self.hidden_size=hidden_size\n",
    "        self.vocab_size=vocab_size\n",
    "        self.rnn=nn.RNN(vocab_size,hidden_size)\n",
    "        self.fn=nn.Linear(hidden_size,vocab_size)\n",
    "    def forward(self,inputs,state):#input:batch_size*seq_len;state:batch_size*hidden_size\n",
    "        X=torch.stack(to_onehot(inputs,self.vocab_size))#X:seq_len,batch_size,vocab_size\n",
    "        Y,state=self.rnn(X,state)\n",
    "        output=self.fn(Y.view(-1,self.hidden_size))#seq_len*batch_size,vocab_size\n",
    "        return output,state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_rnn(prefix,num_chars,model,vocab_size,device,id2char,char2id):\n",
    "    state = None\n",
    "    output = [char2id[prefix[0]]] # output会记录prefix加上输出\n",
    "    for t in range(num_chars + len(prefix) - 1):\n",
    "        X = torch.tensor([output[-1]], device=device).view(1, 1)\n",
    "        if state is not None:\n",
    "            if isinstance(state,tuple):\n",
    "                state=(state[0].to(device),state[1].to(device))\n",
    "            else:\n",
    "                state=state.to(device)\n",
    "        Y,state=model(X,state)\n",
    "        if t<len(prefix)-1:\n",
    "            output.append(prefix[t+1])\n",
    "        else:\n",
    "            output.append(int(Y.argmax(dim=1).item()))\n",
    "    return \"\".join([id2char[i] for i in output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_rnn_pytorch(prefix, num_chars, model, vocab_size, device, idx_to_char,\n",
    "                      char_to_idx):\n",
    "    state = None\n",
    "    output = [char_to_idx[prefix[0]]] # output会记录prefix加上输出\n",
    "    for t in range(num_chars + len(prefix) - 1):\n",
    "        X = torch.tensor([output[-1]], device=device).view(1, 1)\n",
    "        if state is not None:\n",
    "            if isinstance(state, tuple): # LSTM, state:(h, c)  \n",
    "                state = (state[0].to(device), state[1].to(device))\n",
    "            else:   \n",
    "                state = state.to(device)\n",
    "            \n",
    "        (Y, state) = model(X, state)\n",
    "        if t < len(prefix) - 1:\n",
    "            output.append(char_to_idx[prefix[t + 1]])\n",
    "        else:\n",
    "            output.append(int(Y.argmax(dim=1).item()))\n",
    "    return ''.join([idx_to_char[i] for i in output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'分开假间间假假间间假假间'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = RNN(vocab_num, 256).to(device)\n",
    "predict_rnn_pytorch('分开', 10, model, vocab_num, device, id2char, char2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_predict_rnn(model,loss_fn,optimizer,epoch_size,corpus_index,batch_size,device,id2char,char2id,vocab_num):\n",
    "    state=None\n",
    "    for epoch in range(epoch_size):\n",
    "        loss_sum,n=0.0,0\n",
    "        for X,Y in data_iter_consecutive(corpus_index,batch_size=batch_size,num_steps=10,device=device):\n",
    "            if state is not None:\n",
    "                if isinstance(state,tuple):\n",
    "                    state=(state[0].detach(),state[1].detach())\n",
    "                else:\n",
    "                    state=state.detach()\n",
    "            Y_hat,state=model(X,state)\n",
    "            Y=torch.transpose(Y,0,1).contiguous().view(-1)\n",
    "            loss=loss_fn(Y_hat,Y.long())\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss_sum+=loss.item()*Y.shape[0]\n",
    "            n+=Y.shape[0]\n",
    "        print(\"epoch %d,loss:%f\"%(epoch+1,loss_sum/n))\n",
    "        print(\"--\",predict_rnn_pytorch('分开', 10, model, vocab_num, device, id2char, char2id))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model=RNN(vocab_num,256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn=nn.CrossEntropyLoss()\n",
    "optimizer=optim.Adam(model.parameters(),lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1,loss:3.947504\n",
      "-- 分开 我不要的可爱女人 \n",
      "epoch 2,loss:3.852210\n",
      "-- 分开 我不了的可  我知\n",
      "epoch 3,loss:3.689370\n",
      "-- 分开 我不要的可爱女人 \n",
      "epoch 4,loss:3.537514\n",
      "-- 分开 我想你的可爱女人 \n",
      "epoch 5,loss:3.396915\n",
      "-- 分开 我不了的可 女人 \n"
     ]
    }
   ],
   "source": [
    "train_predict_rnn(model,loss_fn,optimizer,5,corpus_index,64,device,id2char,char2id,vocab_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
