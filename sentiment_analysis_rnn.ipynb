{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import Counter\n",
    "from torch import nn\n",
    "from torchtext import vocab\n",
    "from torch import optim\n",
    "from torch.utils import data\n",
    "import time\n",
    "import tarfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['imdb.vocab', 'imdbEr.txt', 'README', 'test', 'train']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\"./data/aclImdb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR=\"./data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path=os.path.join(ROOT_DIR,\"aclImdb\")\n",
    "file_name=os.path.join(ROOT_DIR,\"aclImdb_v1.tar\")\n",
    "if not os.path.exists(file_path):\n",
    "    with tarfile.open(file_name,\"r\") as f:\n",
    "        f.extractall(ROOT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(mode=\"train\",path=\"./data/aclImdb\"):\n",
    "    raw_data=[]\n",
    "    for label in [\"pos\",\"neg\"]:\n",
    "        tag=1 if label==\"pos\" else 0\n",
    "        file_path=os.path.join(path,mode,label)\n",
    "        for file in os.listdir(file_path):\n",
    "            full_name=os.path.join(file_path,file)\n",
    "            with open(full_name,\"rb\") as f:\n",
    "                content=f.read().decode(\"utf-8\").replace(\"\\n\",\" \").lower().split()\n",
    "                raw_data.append((content,tag))\n",
    "    return raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=read_data(\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data=read_data(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vocab(dataset):\n",
    "    counter=Counter([tk for st,_ in dataset for tk in st])\n",
    "    all_vocab=vocab.Vocab(counter=counter,min_freq=5)\n",
    "    return all_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_vocab=get_vocab(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# torchtext的vocab中自动添加unk,pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_lens=[len(d) for d,_ in train_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "233.78720000000001"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(content_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN=300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data,vocab):\n",
    "    def pad(x):\n",
    "        return x[:MAX_LEN] if len(x)>MAX_LEN else x+[vocab.stoi[\"<pad>\"]]*(MAX_LEN-len(x))\n",
    "    features,labels=[],[]\n",
    "    for f,l in data:\n",
    "        features.append(pad([vocab.stoi[w] for w in f]))\n",
    "        labels.append(l)\n",
    "    return torch.tensor(features,dtype=torch.long),torch.tensor(labels,dtype=torch.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset=data.TensorDataset(*preprocess(train_data,all_vocab))\n",
    "test_dataset=data.TensorDataset(*preprocess(test_data,all_vocab))\n",
    "BATCH_SIZE=64\n",
    "train_loader=data.DataLoader(train_dataset,batch_size=BATCH_SIZE,shuffle=True)\n",
    "test_loader=data.DataLoader(test_dataset,batch_size=BATCH_SIZE,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 300]) torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "for s,t in train_loader:\n",
    "    print(s.size(),t.size())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RnnModel(nn.Module):\n",
    "    def __init__(self,vocab_num,input_size,hidden_size,num_layer,bidirection=False):\n",
    "        super(RnnModel,self).__init__()\n",
    "        self.embedding=nn.Embedding(vocab_num,input_size)\n",
    "        self.encoder=nn.LSTM(input_size=input_size,hidden_size=hidden_size,bias=True,num_layers=num_layer,bidirectional=bidirection)\n",
    "        self.linear=nn.Linear(hidden_size*(4 if bidirection else 2),2)\n",
    "    def forward(self,x):\n",
    "        x=self.embedding(x.long()).transpose(1,0)#seq_len,batch_size,embeding_size\n",
    "        outputs,_=self.encoder(x)#outputs:seq_len,batch_size,2*hidden_size\n",
    "        hidden=torch.cat((outputs[0],outputs[-1]),dim=-1)#result:batch_size,4*hidden_size\n",
    "        result=self.linear(hidden)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_SIZE=100\n",
    "HIDDEN_SIZE=200\n",
    "NUM_LAYER=2\n",
    "BIDIRECT=True\n",
    "model=RnnModel(len(all_vocab.itos),input_size=EMBEDDING_SIZE,\n",
    "              hidden_size=HIDDEN_SIZE,num_layer=NUM_LAYER,bidirection=BIDIRECT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word2vec(vocabulary):\n",
    "    glove=vocab.GloVe(name=\"6B\",dim=EMBEDDING_SIZE,cache=os.path.join(ROOT_DIR,\"glove\"))\n",
    "    embedding_matrix=torch.zeros((len(vocabulary.itos),EMBEDDING_SIZE))\n",
    "    pretrain_vector=glove.vectors\n",
    "    oov=0\n",
    "    for i,w in enumerate(vocabulary.stoi):\n",
    "        try:\n",
    "            index=glove.stoi[w]\n",
    "            embedding_matrix[i,:]=pretrain_vector[index,:]\n",
    "        except:\n",
    "            oov+=1\n",
    "    print(\"oov:\",oov)\n",
    "    return embedding_matrix        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oov: 365977\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [-0.0382, -0.2449,  0.7281,  ..., -0.1459,  0.8278,  0.2706],\n",
       "        ...,\n",
       "        [ 0.2512,  0.6499, -0.2465,  ...,  0.0659, -0.9114,  0.4129],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.1752,  0.1468, -0.0800,  ...,  0.1581, -0.6230, -0.2806]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.embedding.weight.data.copy_(get_word2vec(all_vocab))\n",
    "model.embedding.weight.requires_grad_(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr,num_epochs=0.01,5\n",
    "loss=nn.CrossEntropyLoss()\n",
    "optimizer=optim.Adam(list(filter(lambda x:x.requires_grad,model.parameters())),lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net,train_loader,test_loader,lr,num_epoch,device):\n",
    "    net=net.to(device)\n",
    "    loss=nn.CrossEntropyLoss()\n",
    "    optimizer=optim.Adam(list(filter(lambda x:x.requires_grad,net.parameters())),lr=lr)\n",
    "    for epoch in range(num_epoch):\n",
    "        loss_sum,n=0.0,0\n",
    "        for X,Y in train_loader:\n",
    "            Y_hat=net(X.to(device))\n",
    "            l=loss(Y_hat,Y.long().to(device))\n",
    "            optimizer.zero_grad()\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "            loss_sum+=l.cpu().item()\n",
    "            n+=X.size(0)\n",
    "            print(n)\n",
    "        print(\"Epoch:%d,TrainLoss:%.2f\"%(epoch+1,l_sum/n))\n",
    "        loss_sum,n=0.0,0\n",
    "        for X,Y in test_loader:\n",
    "            with torch.no_grad():\n",
    "                Y_hat=net(X.to(device))\n",
    "                l=loss(Y_hat,Y.long().to(device))\n",
    "                loss_sum+=l.cpu().item()\n",
    "                n+=X.size(0)\n",
    "        print(\"TestLoss:%.2f\"%(l_sum/n))             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(net,sentence,vocabulary):\n",
    "    sentence_number=torch.tensor([[vocabulary.stoi[w] for k in sentence.trim().split()]])\n",
    "    result=net(sentence_number).argmax(dim=-1).item()\n",
    "    print(\"%s,predict_result:%s\"%(sentence,\"positive\" if result==1 else \"negative\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n",
      "128\n",
      "192\n",
      "256\n",
      "320\n",
      "384\n",
      "448\n",
      "512\n",
      "576\n",
      "640\n",
      "704\n",
      "768\n",
      "832\n",
      "896\n",
      "960\n",
      "1024\n",
      "1088\n",
      "1152\n",
      "1216\n",
      "1280\n",
      "1344\n",
      "1408\n",
      "1472\n",
      "1536\n",
      "1600\n",
      "1664\n",
      "1728\n",
      "1792\n",
      "1856\n",
      "1920\n",
      "1984\n",
      "2048\n",
      "2112\n",
      "2176\n",
      "2240\n",
      "2304\n",
      "2368\n",
      "2432\n",
      "2496\n",
      "2560\n",
      "2624\n",
      "2688\n",
      "2752\n",
      "2816\n",
      "2880\n",
      "2944\n",
      "3008\n",
      "3072\n",
      "3136\n",
      "3200\n",
      "3264\n",
      "3328\n",
      "3392\n",
      "3456\n",
      "3520\n",
      "3584\n",
      "3648\n",
      "3712\n",
      "3776\n",
      "3840\n",
      "3904\n",
      "3968\n",
      "4032\n",
      "4096\n",
      "4160\n",
      "4224\n",
      "4288\n",
      "4352\n",
      "4416\n",
      "4480\n",
      "4544\n",
      "4608\n",
      "4672\n",
      "4736\n",
      "4800\n",
      "4864\n",
      "4928\n",
      "4992\n",
      "5056\n",
      "5120\n",
      "5184\n",
      "5248\n",
      "5312\n",
      "5376\n",
      "5440\n",
      "5504\n",
      "5568\n",
      "5632\n",
      "5696\n",
      "5760\n",
      "5824\n",
      "5888\n",
      "5952\n",
      "6016\n",
      "6080\n",
      "6144\n",
      "6208\n",
      "6272\n",
      "6336\n",
      "6400\n",
      "6464\n",
      "6528\n",
      "6592\n",
      "6656\n",
      "6720\n",
      "6784\n",
      "6848\n",
      "6912\n",
      "6976\n",
      "7040\n",
      "7104\n",
      "7168\n",
      "7232\n",
      "7296\n",
      "7360\n",
      "7424\n",
      "7488\n",
      "7552\n",
      "7616\n",
      "7680\n",
      "7744\n",
      "7808\n",
      "7872\n",
      "7936\n",
      "8000\n",
      "8064\n",
      "8128\n",
      "8192\n",
      "8256\n",
      "8320\n",
      "8384\n",
      "8448\n",
      "8512\n",
      "8576\n",
      "8640\n",
      "8704\n",
      "8768\n",
      "8832\n",
      "8896\n",
      "8960\n",
      "9024\n",
      "9088\n",
      "9152\n",
      "9216\n",
      "9280\n",
      "9344\n",
      "9408\n",
      "9472\n",
      "9536\n",
      "9600\n",
      "9664\n",
      "9728\n",
      "9792\n",
      "9856\n",
      "9920\n",
      "9984\n",
      "10048\n",
      "10112\n",
      "10176\n",
      "10240\n",
      "10304\n",
      "10368\n",
      "10432\n",
      "10496\n",
      "10560\n",
      "10624\n",
      "10688\n",
      "10752\n",
      "10816\n",
      "10880\n",
      "10944\n",
      "11008\n",
      "11072\n",
      "11136\n",
      "11200\n",
      "11264\n",
      "11328\n",
      "11392\n",
      "11456\n",
      "11520\n",
      "11584\n",
      "11648\n",
      "11712\n",
      "11776\n",
      "11840\n",
      "11904\n",
      "11968\n",
      "12032\n",
      "12096\n",
      "12160\n",
      "12224\n",
      "12288\n",
      "12352\n",
      "12416\n",
      "12480\n",
      "12544\n",
      "12608\n",
      "12672\n",
      "12736\n",
      "12800\n",
      "12864\n",
      "12928\n",
      "12992\n",
      "13056\n",
      "13120\n",
      "13184\n",
      "13248\n",
      "13312\n",
      "13376\n",
      "13440\n",
      "13504\n",
      "13568\n",
      "13632\n",
      "13696\n",
      "13760\n",
      "13824\n",
      "13888\n",
      "13952\n",
      "14016\n",
      "14080\n",
      "14144\n",
      "14208\n",
      "14272\n",
      "14336\n",
      "14400\n",
      "14464\n",
      "14528\n",
      "14592\n",
      "14656\n",
      "14720\n",
      "14784\n",
      "14848\n",
      "14912\n",
      "14976\n",
      "15040\n",
      "15104\n",
      "15168\n",
      "15232\n",
      "15296\n",
      "15360\n",
      "15424\n",
      "15488\n",
      "15552\n",
      "15616\n",
      "15680\n",
      "15744\n",
      "15808\n",
      "15872\n",
      "15936\n",
      "16000\n",
      "16064\n",
      "16128\n",
      "16192\n",
      "16256\n",
      "16320\n",
      "16384\n",
      "16448\n",
      "16512\n",
      "16576\n",
      "16640\n",
      "16704\n",
      "16768\n",
      "16832\n",
      "16896\n",
      "16960\n",
      "17024\n",
      "17088\n",
      "17152\n",
      "17216\n",
      "17280\n",
      "17344\n",
      "17408\n",
      "17472\n",
      "17536\n",
      "17600\n",
      "17664\n",
      "17728\n",
      "17792\n",
      "17856\n",
      "17920\n",
      "17984\n",
      "18048\n",
      "18112\n",
      "18176\n",
      "18240\n",
      "18304\n",
      "18368\n",
      "18432\n",
      "18496\n",
      "18560\n"
     ]
    }
   ],
   "source": [
    "train(model,train_loader,test_loader,lr,num_epochs,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GlobalMaxPool(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GlobalMaxPool,self).__init__()\n",
    "    def forward(self,x):\n",
    "        return nn.functional.max_pool1d(x,kernel_size=x.size(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNModel(nn.Module):\n",
    "    def __init__(self,vocab_size,embeding_size,kernel_sizes,channel_sizes,dropout=0.5):\n",
    "        super(CNNModel,self).__init__()\n",
    "        self.embeding=nn.Embedding(vocab_size,embeding_size)\n",
    "        self.convs=nn.ModuleList()\n",
    "        for kernel,channel in zip(kernel_sizes,channel_sizes):\n",
    "            self.convs.append(nn.Conv1d(in_channels=embeding_size,out_channels=channel,kernel_size=kernel))\n",
    "        self.dropout=nn.Dropout(dropout)\n",
    "        self.maxpool=GlobalMaxPool()\n",
    "        self.linear=nn.Linear(sum(channel_sizes),2)\n",
    "    def forward(self,x):\n",
    "        x=self.embeding(x).premute(0,2,1)\n",
    "        conv_result=[]\n",
    "        for conv in self.convs:\n",
    "            conv_result.append(maxpool(nn.functional.relu(conv(x))).squeeze(-1))\n",
    "        result=torch.cat(conv_result,dim=1)\n",
    "        return self.linear(self.dropout(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
