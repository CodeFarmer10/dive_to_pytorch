{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn,optim\n",
    "from torch.utils import data\n",
    "from torchtext import vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH=\"./data/fr-en-small.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOS=\"<bos>\"\n",
    "EOS=\"<eos>\"\n",
    "PAD=\"<pad>\"\n",
    "UNK=\"<unk>\"\n",
    "MAX_LEN=7\n",
    "EPOCH_SIZE=50\n",
    "BATCH_SIZE=4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(vocabulary,text):\n",
    "    text=text.split()\n",
    "    vocabulary.update(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def token2index(vocabulary,text,target=False):\n",
    "    sentence=[vocabulary.stoi[w] for w in text]\n",
    "    if target:\n",
    "        sentence=sentence[:MAX_LEN-1] if len(sentence)>MAX_LEN-1 else sentence\n",
    "        sentence+=[vocabulary.stoi[EOS]]+[vocabulary.stoi[PAD]]*(MAX_LEN-len(sentence)-1)\n",
    "    else:\n",
    "        sentence=sentence[:MAX_LEN] if len(sentence)>MAX_LEN else sentence\n",
    "        sentence+=[vocabulary.stoi[PAD]]*(MAX_LEN-len(sentence))\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(file_path):\n",
    "    input_vacab,output_vocab=Counter(),Counter()\n",
    "    input_data,output_data=[],[]\n",
    "    input_examples,out_examples=[],[]\n",
    "    \n",
    "    with open(file_path,\"r\") as f:\n",
    "        lines=f.readlines()\n",
    "    for line in lines:\n",
    "        text=line.strip().lower().split(\"\\t\")\n",
    "        fr=text[0]\n",
    "        en=text[1]\n",
    "        input_data.append(tokenize(input_vacab,fr))\n",
    "        output_data.append(tokenize(output_vocab,en))\n",
    "    input_vocabs=vocab.Vocab(input_vacab,specials=[UNK,PAD,BOS,EOS])\n",
    "    output_vocabs=vocab.Vocab(output_vocab,specials=[UNK,PAD,BOS,EOS])\n",
    "  \n",
    "    for input_text,output_text in zip(input_data,output_data):\n",
    "        input_examples.append(token2index(input_vocabs,input_text))\n",
    "        out_examples.append(token2index(output_vocabs,output_text,True))\n",
    "    return input_vocabs,output_vocabs,data.TensorDataset(torch.tensor(input_examples),torch.tensor(out_examples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "fr_vocab,en_vocab,dataset=read_data(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 7,  8, 39,  4,  1,  1,  1]) tensor([ 8,  6, 32,  4,  3,  1,  1])\n"
     ]
    }
   ],
   "source": [
    "print(dataset[5][0],dataset[5][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<unk>', '<pad>', '<bos>', '<eos>', '.', 'est', 'elle', 'ils', 'sont', 'il']\n"
     ]
    }
   ],
   "source": [
    "print(fr_vocab.itos[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<unk>', '<pad>', '<bos>', '<eos>', '.', 'is', 'are', 'he', 'they', 'she']\n"
     ]
    }
   ],
   "source": [
    "print(en_vocab.itos[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型建立"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    '''编码器'''\n",
    "    def __init__(self,vocab_size,embedding_size,hidden_size,num_layer):\n",
    "        super(Encoder,self).__init__()\n",
    "        self.embedding=nn.Embedding(vocab_size,embedding_size)\n",
    "        self.rnn=nn.GRU(input_size=embedding_size,hidden_size=hidden_size,num_layers=num_layer)\n",
    "    def forward(self,x):\n",
    "        embedding=self.embedding(x.long()) #batch_size,seq_len,embedding_size\n",
    "        return self.rnn(embedding.permute(1,0,2))#output: seq_len,batch_size,hidden_size state:batch_size,num_layer*hidden_size  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self,enc_hidden_size,dec_hidden_size,attention_size):\n",
    "        super(Attention,self).__init__()\n",
    "        self.weight=nn.Sequential(nn.Linear(enc_hidden_size+dec_hidden_size,attention_size),\n",
    "                                 nn.Tanh(),\n",
    "                                 nn.Linear(attention_size,1))\n",
    "    def forward(self,encode_output,decode_hidden):\n",
    "        '''\n",
    "        encode_output:seq_len,batch_size,hidden_size\n",
    "        decode_hidden:batch_size,hidden_size\n",
    "        \n",
    "        '''\n",
    "        decode_hidden=decode_hidden.unsqueeze(dim=0).expand_as(encode_output)\n",
    "        w=nn.functional.softmax(self.weight(torch.cat((encode_output,decode_hidden),dim=2)),dim=0)#  seq_len,batch_size,1\n",
    "        return (w*encode_output).sum(dim=0)# batch_size,hidden_size\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self,vocab_size,embedding_size,enc_hidden_size,dec_hidden_size,attention_size,num_layers):\n",
    "        super(Decoder,self).__init__()\n",
    "        self.embedding=nn.Embedding(vocab_size,embedding_size)\n",
    "        self.attention=Attention(enc_hidden_size,dec_hidden_size,attention_size)\n",
    "        self.rnn=nn.GRU(embedding_size+enc_hidden_size,dec_hidden_size,num_layers=num_layers)\n",
    "        self.linear=nn.Linear(dec_hidden_size,vocab_size)\n",
    "    def forward(self,x,encoder_output,state=None):\n",
    "        '''\n",
    "        x:batch_size,\n",
    "        encoder_output:seq_len,batch_size,hidden_size\n",
    "        state:num_layer,batch_size,hidden_size\n",
    "        '''\n",
    "        embedding=self.embedding(x.long())  #batch_size,embedding_size\n",
    "        attention=self.attention(encoder_output,state[-1])# batch_size,hidden_size\n",
    "        output,state=self.rnn((torch.cat((embedding,attention),dim=1)).unsqueeze(dim=0),state) #output:1,batch_size,hidden_size;state:num_layer,batch_size,hidden_size\n",
    "        return self.linear(output).squeeze(dim=0),state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batchloss(encoder,decoder,source,target,loss):\n",
    "    outputs=[]\n",
    "    batch_size=source.size(0)\n",
    "    encoder_output,state=encoder(source)\n",
    "    decoder_input=torch.ones(batch_size,)*en_vocab.stoi[BOS]\n",
    "    for Y in target.permute(1,0):\n",
    "        output,state=decoder(decoder_input,encoder_output,state)\n",
    "        outputs.append(output)\n",
    "        decoder_input=Y\n",
    "    predict=torch.stack(outputs).permute(1,0,2).contiguous().view(-1,len(en_vocab)) #batch_size*seq_len,vocab_size\n",
    "    label=target.view(-1,)\n",
    "    mask=(label!=en_vocab.stoi[PAD]).float()\n",
    "    return (loss(predict,label)*mask).sum()/mask.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_loss(encoder, decoder, X, Y, loss):\n",
    "    batch_size = X.shape[0]\n",
    "    enc_outputs, enc_state = encoder(X)\n",
    "    # 初始化解码器的隐藏状态\n",
    "    dec_state = enc_state\n",
    "    # 解码器在最初时间步的输入是BOS\n",
    "    dec_input = torch.tensor([en_vocab.stoi[BOS]] * batch_size)\n",
    "    # 我们将使用掩码变量mask来忽略掉标签为填充项PAD的损失\n",
    "    mask, num_not_pad_tokens = torch.ones(batch_size,), 0\n",
    "    l = torch.tensor([0.0])\n",
    "    for y in Y.permute(1,0): # Y shape: (batch, seq_len)\n",
    "        dec_output, dec_state = decoder(dec_input, enc_outputs,dec_state)\n",
    "        l = l + (mask * loss(dec_output, y)).sum()\n",
    "        dec_input = y  # 使用强制教学\n",
    "        num_not_pad_tokens += mask.sum().item()\n",
    "        # EOS后面全是PAD. 下面一行保证一旦遇到EOS接下来的循环中mask就一直是0\n",
    "        mask = mask * (y != en_vocab.stoi[EOS]).float()\n",
    "    return l / num_not_pad_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(encoder,decoder,source_vocab,target_vocab,dataset):\n",
    "    encoder_optim=optim.Adam(encoder.parameters(),lr=0.01)\n",
    "    decoder_optim=optim.Adam(decoder.parameters(),lr=0.01)\n",
    "    loss=nn.CrossEntropyLoss(reduction=\"none\")\n",
    "    dataloader=data.DataLoader(dataset=dataset,batch_size=BATCH_SIZE,shuffle=True)\n",
    "    for epoch in range(EPOCH_SIZE):\n",
    "        l_sum=0\n",
    "        for X,Y in dataloader:\n",
    "            encoder_optim.zero_grad()\n",
    "            decoder_optim.zero_grad()\n",
    "            l=batchloss(encoder,decoder,X,Y,loss)\n",
    "            l.backward()\n",
    "            encoder_optim.step()\n",
    "            decoder_optim.step()\n",
    "            l_sum+=l.cpu().item()\n",
    "        print(\"Epoch:%d,Loss:%f\"%(epoch+1,l_sum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1,Loss:15.396118\n",
      "Epoch:2,Loss:10.650159\n",
      "Epoch:3,Loss:7.820441\n",
      "Epoch:4,Loss:6.193841\n",
      "Epoch:5,Loss:5.002726\n",
      "Epoch:6,Loss:4.024870\n",
      "Epoch:7,Loss:3.434067\n",
      "Epoch:8,Loss:2.930856\n",
      "Epoch:9,Loss:2.576673\n",
      "Epoch:10,Loss:2.305188\n",
      "Epoch:11,Loss:1.944704\n",
      "Epoch:12,Loss:1.913826\n",
      "Epoch:13,Loss:1.598700\n",
      "Epoch:14,Loss:1.716502\n",
      "Epoch:15,Loss:1.410523\n",
      "Epoch:16,Loss:1.260203\n",
      "Epoch:17,Loss:1.108375\n",
      "Epoch:18,Loss:0.974600\n",
      "Epoch:19,Loss:0.855859\n",
      "Epoch:20,Loss:0.779932\n",
      "Epoch:21,Loss:0.692020\n",
      "Epoch:22,Loss:0.666504\n",
      "Epoch:23,Loss:0.587369\n",
      "Epoch:24,Loss:0.535799\n",
      "Epoch:25,Loss:0.485055\n",
      "Epoch:26,Loss:0.432214\n",
      "Epoch:27,Loss:0.407595\n",
      "Epoch:28,Loss:0.388035\n",
      "Epoch:29,Loss:0.338016\n",
      "Epoch:30,Loss:0.350799\n",
      "Epoch:31,Loss:0.376195\n",
      "Epoch:32,Loss:0.280863\n",
      "Epoch:33,Loss:0.275644\n",
      "Epoch:34,Loss:0.257240\n",
      "Epoch:35,Loss:0.218947\n",
      "Epoch:36,Loss:0.198931\n",
      "Epoch:37,Loss:0.168688\n",
      "Epoch:38,Loss:0.163474\n",
      "Epoch:39,Loss:0.146729\n",
      "Epoch:40,Loss:0.129693\n",
      "Epoch:41,Loss:0.158469\n",
      "Epoch:42,Loss:0.128901\n",
      "Epoch:43,Loss:0.105476\n",
      "Epoch:44,Loss:0.093692\n",
      "Epoch:45,Loss:0.082850\n",
      "Epoch:46,Loss:0.072447\n",
      "Epoch:47,Loss:0.069617\n",
      "Epoch:48,Loss:0.061291\n",
      "Epoch:49,Loss:0.055596\n",
      "Epoch:50,Loss:0.058972\n"
     ]
    }
   ],
   "source": [
    "EMBEDDING_SIZE=64\n",
    "HIDDEN_SIZE=64\n",
    "ATTENTION_SIZE=10\n",
    "encoder=Encoder(len(fr_vocab),EMBEDDING_SIZE,HIDDEN_SIZE,2)\n",
    "decoder=Decoder(len(en_vocab),EMBEDDING_SIZE,HIDDEN_SIZE,HIDDEN_SIZE,ATTENTION_SIZE,2)\n",
    "train(encoder,decoder,fr_vocab,en_vocab,dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(encoder,decoder,fr_vocab,en_vocab,source_text):\n",
    "    in_seq=source_text.strip().split()\n",
    "    in_seq=torch.tensor([[fr_vocab.stoi[w] for w in in_seq]])\n",
    "    encoder_output,state=encoder(in_seq)\n",
    "    Y=torch.tensor([en_vocab.stoi[BOS]])\n",
    "    target=[]\n",
    "    while len(target)<MAX_LEN:\n",
    "        decoder_output,state=decoder(Y,encoder_output,state)\n",
    "        w=decoder_output.argmax(dim=1).item()\n",
    "        if w==en_vocab.stoi[EOS]:\n",
    "            break\n",
    "        else:\n",
    "            target.append(w)\n",
    "            Y=torch.tensor([w])\n",
    "    target_text=\" \".join([en_vocab.itos[i] for i in target])\n",
    "    print(\"French:%s   English:%s\"%(source_text,target_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "French:ils crevees .   English:they are exhausted .\n"
     ]
    }
   ],
   "source": [
    "translate(encoder,decoder,fr_vocab,en_vocab,\"ils crevees .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39\n"
     ]
    }
   ],
   "source": [
    "print(len(en_vocab.itos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<unk>', '<pad>', '<bos>', '<eos>', '.', 'est', 'elle', 'ils', 'sont', 'il', 'mon', 'a', 'c', 'elles', '!', 'acteurs', 'adorable', 'age', 'amis', 'bonne', 'bonnes', 'canadienne', 'crevees', 'de', 'des', 'deux', 'disputent', 'du', 'ennuis', 'environ', 'fait', 'frere', 'genre', 'grands', 'japonaise', 'nageuse', 'oncle', 'personne', 'regardent', 'russes', 'se', 'tort', 'toutes', 'tranquille', 'une', 'velo', 'vieille']\n"
     ]
    }
   ],
   "source": [
    "print(fr_vocab.itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blue_score(label,predict,k=2):\n",
    "    label_len,predict_len=len(label),len(predict)\n",
    "    score=math.exp(min(0,1-label_len/predict_len))\n",
    "    for i in range(1,k+1):\n",
    "        num_match=0\n",
    "        label_subs=collections.defaultdict(int)\n",
    "        for j in range(label_len-i+1):\n",
    "            label_subs[\"\".join(label[j:j+i])]+=1\n",
    "        for j in range(predict_len-i+1):\n",
    "            sub=\"\".join(predict[j:j+i])\n",
    "            if label_subs[sub]>0:\n",
    "                num_match+=1\n",
    "                label_subs[sub]-=1 \n",
    "        score*=math.pow(num_match/(predict_len-i+1),math.pow(1/2,i))\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6025286104785453\n"
     ]
    }
   ],
   "source": [
    "in_seq='they are watching .'.split()\n",
    "out_seq='they are .'.split()\n",
    "print(blue_score(in_seq,out_seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
